{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.s3 import S3Downloader\n",
    "import json\n",
    "import jsonlines\n",
    "import utils\n",
    "from importlib import reload\n",
    "\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session = sagemaker.Session()\n",
    "\n",
    "endpoint_name = \"index-predictor-endpoint\"\n",
    "feature_group_name = \"index-predictor-feature-group-v7\"\n",
    "bucket_name = \"team1-index-predictor-bucket\"\n",
    "data_version = \"2024-06-26-09-33\"\n",
    "\n",
    "data_capture_prefix = \"data-capture\"\n",
    "data_capture_s3_url = f\"s3://{bucket_name}/{data_capture_prefix}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=CSVSerializer(),\n",
    "    deserializer=CSVDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading data from feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group = FeatureGroup(name=feature_group_name, sagemaker_session=sm_session)\n",
    "\n",
    "query = feature_group.athena_query()\n",
    "\n",
    "query.run(\n",
    "    query_string=f\"SELECT * FROM {feature_group_name} WHERE version = '{data_version}'\",\n",
    "    output_location=f\"s3://{bucket_name}/model_monitor/data/\",\n",
    ")\n",
    "\n",
    "query.wait()\n",
    "\n",
    "df = query.as_dataframe()\n",
    "\n",
    "train_df = df[df[\"type\"] == \"train\"].copy()\n",
    "validation_df = df[df[\"type\"] == \"validation\"].copy()\n",
    "test_df = df[df[\"type\"] == \"test\"].copy()\n",
    "\n",
    "selected_test_df = test_df.copy().sample(n=100, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"type\", \"version\", \"write_time\", \"api_invocation_time\", \"is_deleted\"]\n",
    "\n",
    "df.drop(\n",
    "    columns=columns_to_drop,\n",
    "    inplace=True,\n",
    ")\n",
    "train_df.drop(\n",
    "    columns=columns_to_drop,\n",
    "    inplace=True,\n",
    ")\n",
    "validation_df.drop(\n",
    "    columns=columns_to_drop,\n",
    "    inplace=True,\n",
    ")\n",
    "test_df.drop(\n",
    "    columns=columns_to_drop,\n",
    "    inplace=True,\n",
    ")\n",
    "selected_test_df.drop(\n",
    "    columns=columns_to_drop,\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.generate_endpoint_traffic(predictor, selected_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_files = utils.get_file_list(bucket_name, data_capture_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_key = capture_files[-1]\n",
    "S3Downloader.download(f\"s3://{bucket_name}/{file_key}\", f\"./tmp\")\n",
    "\n",
    "print(f\"Content of the capture file:\")\n",
    "with jsonlines.open(f\"./tmp/{file_key.split('/')[-1]}\") as reader:\n",
    "    print(json.dumps(reader.read(), indent=2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "394b8241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Using cached alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Using cached colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.12/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from optuna) (24.1)\n",
      "Collecting sqlalchemy>=1.3.0 (from optuna)\n",
      "  Downloading SQLAlchemy-2.0.30-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting tqdm (from optuna)\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting PyYAML (from optuna)\n",
      "  Using cached PyYAML-6.0.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4 (from alembic>=1.5.0->optuna)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting MarkupSafe>=0.9.2 (from Mako->alembic>=1.5.0->optuna)\n",
      "  Using cached MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
      "Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "Downloading SQLAlchemy-2.0.30-cp312-cp312-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Using cached PyYAML-6.0.1-cp312-cp312-macosx_11_0_arm64.whl (165 kB)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_universal2.whl (18 kB)\n",
      "Installing collected packages: typing-extensions, tqdm, PyYAML, MarkupSafe, colorlog, sqlalchemy, Mako, alembic, optuna\n",
      "Successfully installed Mako-1.3.5 MarkupSafe-2.1.5 PyYAML-6.0.1 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1 sqlalchemy-2.0.30 tqdm-4.66.4 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb3513a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from optuna import create_study\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4e78b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"team1-index-predictor-bucket\"\n",
    "\n",
    "root_folder = \"data/processed\"\n",
    "\n",
    "train_data_filename = \"train-v0.csv\"\n",
    "validation_data_filename = \"validation-v0.csv\"\n",
    "test_data_filename = \"test-v0.csv\"\n",
    "\n",
    "s3 = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c864d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s3_object = s3.get_object(Bucket=BUCKET_NAME, Key=train_raw_data_filename)\n",
    "validation_s3_object = s3.get_object(\n",
    "    Bucket=BUCKET_NAME, Key=validation_raw_data_filename\n",
    ")\n",
    "test_s3_object = s3.get_object(Bucket=BUCKET_NAME, Key=test_raw_data_filename)\n",
    "\n",
    "train_data = train_s3_object[\"Body\"].read().decode(\"utf-8\")\n",
    "train_df = pd.read_csv(StringIO(train_data))\n",
    "\n",
    "validation_data = validation_s3_object[\"Body\"].read().decode(\"utf-8\")\n",
    "validation_df = pd.read_csv(StringIO(validation_data))\n",
    "\n",
    "test_data = test_s3_object[\"Body\"].read().decode(\"utf-8\")\n",
    "test_df = pd.read_csv(StringIO(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0e86cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"../{root_folder}/{train_data_filename}\")\n",
    "validation_df = pd.read_csv(f\"../{root_folder}/{validation_data_filename}\")\n",
    "test_df = pd.read_csv(f\"../{root_folder}/{test_data_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13d2e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"Close_target\"])\n",
    "y_train = train_df[\"Close_target\"]\n",
    "\n",
    "X_validation = validation_df.drop(columns=[\"Close_target\"])\n",
    "y_validation = validation_df[\"Close_target\"]\n",
    "\n",
    "X_test = test_df.drop(columns=[\"Close_target\"])\n",
    "y_test = test_df[\"Close_target\"]\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalidation = xgb.DMatrix(X_validation, label=y_validation)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d6d2c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'learning_rate': 0.01759489987922903, 'num_boost_round': 93}\n",
      "Validation Accuracy: 53.33%\n",
      "Test Accuracy: 47.78%\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "optuna_logger = logging.getLogger(\"optuna\")\n",
    "optuna_logger.setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 1e-1, log=True),\n",
    "        \"eval_metric\": \"logloss\",\n",
    "    }\n",
    "    num_boost_round = trial.suggest_int(\"num_boost_round\", 50, 100)\n",
    "\n",
    "    evals = [(dtrain, \"train\"), (dvalidation, \"eval\")]\n",
    "\n",
    "    bst = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        evals=evals,\n",
    "        early_stopping_rounds=20,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    y_pred_validation = bst.predict(dvalidation)\n",
    "    y_pred_validation_binary = (y_pred_validation > 0.5).astype(int)\n",
    "\n",
    "    validation_accuracy = accuracy_score(y_validation, y_pred_validation_binary)\n",
    "\n",
    "    return validation_accuracy\n",
    "\n",
    "\n",
    "study = create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(study.best_params)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"max_depth\": best_params[\"max_depth\"],\n",
    "    \"learning_rate\": best_params[\"learning_rate\"],\n",
    "    \"eval_metric\": \"logloss\",\n",
    "}\n",
    "\n",
    "evals = [(dtrain, \"train\"), (dvalidation, \"eval\")]\n",
    "\n",
    "bst = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=best_params[\"num_boost_round\"],\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=10,\n",
    "    verbose_eval=False,\n",
    ")\n",
    "\n",
    "y_pred_validation = bst.predict(dvalidation)\n",
    "y_pred_test = bst.predict(dtest)\n",
    "\n",
    "y_pred_validation_binary = (y_pred_validation > 0.5).astype(int)\n",
    "y_pred_test_binary = (y_pred_test > 0.5).astype(int)\n",
    "\n",
    "validation_accuracy = accuracy_score(y_validation, y_pred_validation_binary)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test_binary)\n",
    "\n",
    "print(f\"Validation Accuracy: {validation_accuracy*100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a34f412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative return: -0.0032180125650403723\n",
      "Cumulative reward: -17.5595703125\n"
     ]
    }
   ],
   "source": [
    "def compute_cumulative_reward(y_pred, close_prices):\n",
    "    \"\"\"Get the cumulative, reward, since the model predicts if at time t+3 the price will be higher\n",
    "    or lower than at time t, if model predicts correctly, we get the difference between the price at\n",
    "    time t+3 and t, if the model predicts incorrectly, we get the negative difference between the\n",
    "    price at time t+3 and t\"\"\"\n",
    "    rewards = []\n",
    "    for i in range(0, len(close_prices) - 3):\n",
    "        if y_pred[i] == 1:\n",
    "            rewards.append(close_prices[i + 3] - close_prices[i])\n",
    "        else:\n",
    "            rewards.append(close_prices[i] - close_prices[i + 3])\n",
    "    return np.sum(rewards)\n",
    "\n",
    "\n",
    "def compute_cumulative_return(y_pred, close_prices):\n",
    "    \"\"\"Similar to the compute_cumulative_reward function, but in percentage terms\"\"\"\n",
    "    rewards = []\n",
    "    for i in range(0, len(close_prices) - 3):\n",
    "        if y_pred[i] == 1:\n",
    "            rewards.append((close_prices[i + 3] - close_prices[i]) / close_prices[i])\n",
    "        else:\n",
    "            rewards.append((close_prices[i] - close_prices[i + 3]) / close_prices[i])\n",
    "    return np.sum(rewards)\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Cumulative return:\",\n",
    "    compute_cumulative_return(y_pred_test_binary, test_df[\"Close\"].values),\n",
    ")\n",
    "print(\n",
    "    \"Cumulative reward:\",\n",
    "    compute_cumulative_reward(y_pred_test_binary, test_df[\"Close\"].values),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e2caf844",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = \"model_xgb_v0_0_1.xgb\"\n",
    "model_folder = \"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "539dc2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir -p ../models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "504858e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/humbertoyusta/classes/mlops/index-predictor/venv/lib/python3.12/site-packages/xgboost/core.py:160: UserWarning: [22:51:35] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "\n",
    "bst.save_model(f\"../{model_folder}/{model_filename}\")\n",
    "\n",
    "with tarfile.open(f\"../{model_folder}/{model_filename}.tar.gz\", \"w:gz\") as tar:\n",
    "    tar.add(f\"../{model_folder}/{model_filename}\", arcname=model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1d0ef481",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.save_model(f\"../models/{model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c681451",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.upload_file(\n",
    "    model_filename,\n",
    "    BUCKET_NAME,\n",
    "    f\"models/{model_filename}\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

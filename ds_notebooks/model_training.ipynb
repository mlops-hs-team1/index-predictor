{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed8c2c7-b83b-483a-9bc7-c5c1f035e164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Using cached alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Using cached colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.12/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from optuna) (24.1)\n",
      "Collecting sqlalchemy>=1.3.0 (from optuna)\n",
      "  Downloading SQLAlchemy-2.0.30-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting tqdm (from optuna)\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting PyYAML (from optuna)\n",
      "  Using cached PyYAML-6.0.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4 (from alembic>=1.5.0->optuna)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting MarkupSafe>=0.9.2 (from Mako->alembic>=1.5.0->optuna)\n",
      "  Using cached MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
      "Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "Downloading SQLAlchemy-2.0.30-cp312-cp312-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Using cached PyYAML-6.0.1-cp312-cp312-macosx_11_0_arm64.whl (165 kB)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_universal2.whl (18 kB)\n",
      "Installing collected packages: typing-extensions, tqdm, PyYAML, MarkupSafe, colorlog, sqlalchemy, Mako, alembic, optuna\n",
      "Successfully installed Mako-1.3.5 MarkupSafe-2.1.5 PyYAML-6.0.1 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1 sqlalchemy-2.0.30 tqdm-4.66.4 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7945d4c0-0ae8-4522-9b09-b14ee4284147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from optuna import create_study\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "555069e3-53f7-4f4e-882d-bd7a41d2c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"team1-index-predictor-bucket\"\n",
    "\n",
    "root_folder = \"data/processed\"\n",
    "\n",
    "train_data_filename = \"train.csv\"\n",
    "validation_data_filename = \"validation.csv\"\n",
    "test_data_filename = \"test.csv\"\n",
    "\n",
    "s3 = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6ab267f0-433a-4dfd-b7b9-a517568edd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s3_object = s3.get_object(Bucket=BUCKET_NAME, Key=train_raw_data_filename)\n",
    "validation_s3_object = s3.get_object(\n",
    "    Bucket=BUCKET_NAME, Key=validation_raw_data_filename\n",
    ")\n",
    "test_s3_object = s3.get_object(Bucket=BUCKET_NAME, Key=test_raw_data_filename)\n",
    "\n",
    "train_data = train_s3_object[\"Body\"].read().decode(\"utf-8\")\n",
    "train_df = pd.read_csv(StringIO(train_data))\n",
    "\n",
    "validation_data = validation_s3_object[\"Body\"].read().decode(\"utf-8\")\n",
    "validation_df = pd.read_csv(StringIO(validation_data))\n",
    "\n",
    "test_data = test_s3_object[\"Body\"].read().decode(\"utf-8\")\n",
    "test_df = pd.read_csv(StringIO(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5066e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"../{root_folder}/{train_data_filename}\")\n",
    "validation_df = pd.read_csv(f\"../{root_folder}/{validation_data_filename}\")\n",
    "test_df = pd.read_csv(f\"../{root_folder}/{test_data_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86c151ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"Close_target\"])\n",
    "y_train = train_df[\"Close_target\"]\n",
    "\n",
    "X_validation = validation_df.drop(columns=[\"Close_target\"])\n",
    "y_validation = validation_df[\"Close_target\"]\n",
    "\n",
    "X_test = test_df.drop(columns=[\"Close_target\"])\n",
    "y_test = test_df[\"Close_target\"]\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalidation = xgb.DMatrix(X_validation, label=y_validation)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "42cd79a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.68899\teval-logloss:0.69523\n",
      "[1]\ttrain-logloss:0.68183\teval-logloss:0.69666\n",
      "[2]\ttrain-logloss:0.67837\teval-logloss:0.69755\n",
      "[3]\ttrain-logloss:0.67141\teval-logloss:0.69968\n",
      "[4]\ttrain-logloss:0.66877\teval-logloss:0.70009\n",
      "[5]\ttrain-logloss:0.66355\teval-logloss:0.70116\n",
      "[6]\ttrain-logloss:0.65817\teval-logloss:0.70258\n",
      "[7]\ttrain-logloss:0.65664\teval-logloss:0.70325\n",
      "[8]\ttrain-logloss:0.65107\teval-logloss:0.70276\n",
      "[9]\ttrain-logloss:0.64679\teval-logloss:0.70309\n",
      "[10]\ttrain-logloss:0.64381\teval-logloss:0.70407\n",
      "Validation Accuracy: 48.61%\n",
      "Test Accuracy: 52.22%\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter dictionary\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"max_depth\": 6,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"eval_metric\": \"logloss\",\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "evals = [(dtrain, \"train\"), (dvalidation, \"eval\")]\n",
    "bst = xgb.train(\n",
    "    params, dtrain, num_boost_round=100, evals=evals, early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "# Make predictions on the validation and test sets\n",
    "y_pred_validation = bst.predict(dvalidation)\n",
    "y_pred_test = bst.predict(dtest)\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred_validation_binary = (y_pred_validation > 0.5).astype(int)\n",
    "y_pred_test_binary = (y_pred_test > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "validation_accuracy = accuracy_score(y_validation, y_pred_validation_binary)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test_binary)\n",
    "\n",
    "print(f\"Validation Accuracy: {validation_accuracy*100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "01db614d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'learning_rate': 0.06051875312554363, 'num_boost_round': 85}\n",
      "Validation Accuracy: 53.06%\n",
      "Test Accuracy: 53.61%\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "optuna_logger = logging.getLogger(\"optuna\")\n",
    "optuna_logger.setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 1e-1, log=True),\n",
    "        \"eval_metric\": \"logloss\",\n",
    "    }\n",
    "    num_boost_round = trial.suggest_int(\"num_boost_round\", 50, 200)\n",
    "\n",
    "    evals = [(dtrain, \"train\"), (dvalidation, \"eval\")]\n",
    "\n",
    "    bst = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        evals=evals,\n",
    "        early_stopping_rounds=10,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    y_pred_validation = bst.predict(dvalidation)\n",
    "    y_pred_validation_binary = (y_pred_validation > 0.5).astype(int)\n",
    "\n",
    "    validation_accuracy = accuracy_score(y_validation, y_pred_validation_binary)\n",
    "\n",
    "    return validation_accuracy\n",
    "\n",
    "\n",
    "study = create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(study.best_params)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"max_depth\": best_params[\"max_depth\"],\n",
    "    \"learning_rate\": best_params[\"learning_rate\"],\n",
    "    \"eval_metric\": \"logloss\",\n",
    "}\n",
    "\n",
    "evals = [(dtrain, \"train\"), (dvalidation, \"eval\")]\n",
    "\n",
    "bst = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=best_params[\"num_boost_round\"],\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=10,\n",
    "    verbose_eval=False,\n",
    ")\n",
    "\n",
    "y_pred_validation = bst.predict(dvalidation)\n",
    "y_pred_test = bst.predict(dtest)\n",
    "\n",
    "y_pred_validation_binary = (y_pred_validation > 0.5).astype(int)\n",
    "y_pred_test_binary = (y_pred_test > 0.5).astype(int)\n",
    "\n",
    "validation_accuracy = accuracy_score(y_validation, y_pred_validation_binary)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test_binary)\n",
    "\n",
    "print(f\"Validation Accuracy: {validation_accuracy*100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d66fc1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = \"xgboost_model.v0.0.1.json\"\n",
    "bst.save_model(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ea812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.upload_file(\n",
    "    model_filename,\n",
    "    BUCKET_NAME,\n",
    "    f\"models/{model_filename}\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch import nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = \"data/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>DayOfWeek_0</th>\n",
       "      <th>DayOfWeek_1</th>\n",
       "      <th>DayOfWeek_2</th>\n",
       "      <th>DayOfWeek_3</th>\n",
       "      <th>DayOfWeek_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.928917</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.921224</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.924498</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.925564</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.925523</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Close  Hour  Minute  DayOfWeek_0  DayOfWeek_1  DayOfWeek_2  DayOfWeek_3  \\\n",
       "0  0.928917    15      29            0            0            0            0   \n",
       "1  0.921224    15      30            0            0            0            0   \n",
       "2  0.924498    15      31            0            0            0            0   \n",
       "3  0.925564    15      32            0            0            0            0   \n",
       "4  0.925523    15      33            0            0            0            0   \n",
       "\n",
       "   DayOfWeek_4  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data for inference should be loaded from online feature store\n",
    "inference_df = pd.read_csv(f\"../{root_folder}/inference.csv\")\n",
    "inference_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def create_lag_features(df, lag=1):\n",
    "    for i in range(1, lag + 1):\n",
    "        df[f\"lag_{i}\"] = df[\"Close\"].shift(i)\n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(1, 64, batch_first=True)\n",
    "        self.linear = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        lstm_out = lstm_out[:, -1, :]  # Get the output of the last timestep\n",
    "        out = self.linear(lstm_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(1, 64, batch_first=True)\n",
       "  (linear): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag = 30\n",
    "\n",
    "inference_df = create_lag_features(inference_df, lag)\n",
    "\n",
    "model = LSTMModel()\n",
    "# Model should be loaded from model registry\n",
    "model.load_state_dict(torch.load(\"lstm_model.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def get_next_minute(hour: int, minute: int, day_of_week: int):\n",
    "    \"\"\"Gets the next minute where S&P500 is open.\"\"\"\n",
    "    minute += 1\n",
    "\n",
    "    if minute == 60:\n",
    "        minute = 0\n",
    "        hour += 1\n",
    "\n",
    "        if hour == 16:\n",
    "            hour = 9\n",
    "            minute = 30\n",
    "            day_of_week = (day_of_week + 1) % 5\n",
    "\n",
    "    return hour, minute, day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def get_next_minute_row(df_row):\n",
    "    \"\"\"Move Close to lag_1, lag_1 to lag_2, etc. set the time (DayOfWeek, Hour and Minute) to\n",
    "    the next minute where S&P500 is open.\"\"\"\n",
    "\n",
    "    for i in range(lag, 1, -1):\n",
    "        df_row[f\"lag_{i}\"] = df_row[f\"lag_{i - 1}\"]\n",
    "\n",
    "    df_row[\"lag_1\"] = df_row[\"Close\"]\n",
    "\n",
    "    day_of_week = -1\n",
    "    for i in range(0, 5):\n",
    "        if df_row[f\"DayOfWeek_{i}\"] == 1:\n",
    "            day_of_week = i\n",
    "            df_row[f\"DayOfWeek_{i}\"] = 0\n",
    "            break\n",
    "\n",
    "    next_min, next_hour, next_day_of_week = get_next_minute(\n",
    "        df_row[\"Hour\"], df_row[\"Minute\"], day_of_week\n",
    "    )\n",
    "\n",
    "    df_row[\"Hour\"] = next_hour\n",
    "    df_row[\"Minute\"] = next_min\n",
    "    df_row[f\"DayOfWeek_{next_day_of_week}\"] = 1\n",
    "\n",
    "    return df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/processed/scaler_params.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# scaler params should be loaded from feature store\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/processed/scaler_params.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m     scaler_params \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      7\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n",
      "File \u001b[0;32m~/classes/mlops/index-predictor/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/processed/scaler_params.json'"
     ]
    }
   ],
   "source": [
    "# scaler params should be loaded from feature store\n",
    "import json\n",
    "\n",
    "with open(\"../data/processed/scaler_params.json\", \"r\") as f:\n",
    "    scaler_params = json.load(f)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.min_, scaler.scale_ = scaler_params[\"min_\"], scaler_params[\"scale_\"]\n",
    "scaler.data_min_, scaler.data_max_ = (\n",
    "    scaler_params[\"data_min\"],\n",
    "    scaler_params[\"data_max\"],\n",
    ")\n",
    "scaler.data_range_ = scaler_params[\"data_range\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 1: 5428.233522772789\n",
      "Day 2: 5428.180880308151\n",
      "Day 3: 5428.444394826889\n",
      "Day 4: 5428.239989757538\n",
      "Day 5: 5428.505559206009\n",
      "Day 6: 5428.232827723026\n",
      "Day 7: 5428.382595837116\n",
      "Day 8: 5427.917637765408\n",
      "Day 9: 5428.105784714222\n",
      "Day 10: 5427.675216495991\n"
     ]
    }
   ],
   "source": [
    "forecast_length = 10\n",
    "\n",
    "last_minute_row = inference_df.iloc[-1].copy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(forecast_length):\n",
    "        next_minute_row = get_next_minute_row(last_minute_row.copy())\n",
    "        next_minute_row = next_minute_row.drop(\"Close\")\n",
    "        input_tensor = torch.tensor(\n",
    "            next_minute_row.values.reshape(1, lag + 7, 1), dtype=torch.float32\n",
    "        )\n",
    "        forecast = model(input_tensor).item()\n",
    "        print(f\"Day {i + 1}: {scaler.inverse_transform([[forecast]])[0][0]}\")\n",
    "        next_minute_row[\"Close\"] = forecast\n",
    "        last_minute_row = next_minute_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
